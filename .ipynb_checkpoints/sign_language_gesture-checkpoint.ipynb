{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TcGdjGUDYniD"
   },
   "source": [
    "# Introduction:\n",
    "\n",
    "this dataset contains A-Z and 0-9 hand gestures which im going to use it to create a pipline or gesture recognition system using Neural network. i have used three models to create this pipline and out of the three i chose the best model with the highest accuracy and score.\n",
    "the URL to the dataset is below and every step has been explained below one by one.\n",
    "\n",
    "link to the url:\n",
    "\n",
    "https://www.kaggle.com/datasets/ahmedkhanak1995/sign-language-gesture-images-dataset/data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ayu8DYrGcmua"
   },
   "source": [
    "# Uploading File\n",
    "In the following i'm uploading the dataset directly from kaggle to do that i need to use my kaggle credential therefor have to download the json file first and only then i can access the dataset on kaggle. the file goes under content folder in my drive and then we can unzip it for further procedures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 92
    },
    "id": "SSzBQEp_Mgbw",
    "outputId": "6664ec0a-d266-472f-b6a4-4f6070c9b994"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-f1598d52-d25e-4ff7-95a5-67b415499471\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-f1598d52-d25e-4ff7-95a5-67b415499471\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving kaggle.json to kaggle.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'kaggle.json': b'{\"username\":\"habibsh\",\"key\":\"3c414fb09cc76110ee8ad631ec963f64\"}'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.colab import files\n",
    "files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "krUCDr7cMhzK",
    "outputId": "1ef55b98-633d-4196-d4bd-4e4910898fac"
   },
   "outputs": [],
   "source": [
    "!pip install kaggle\n",
    "\n",
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "\n",
    "!kaggle datasets download -d ahmedkhanak1995/sign-language-gesture-images-dataset\n",
    "\n",
    "!unzip sign-language-gesture-images-dataset.zip -d /content/\n",
    "\n",
    "from IPython.display import clear_output\n",
    "clear_output()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ffxAPFUecl3m"
   },
   "source": [
    "# Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "9mF_mIzHMkG8"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications import VGG16, DenseNet121\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l_MhjH4A58a8"
   },
   "source": [
    "# Loading and Preprocessing Data\n",
    "since we have iploaded the dataset directly from kaggle using our credentials. we have to give the dataset path which is located in the content\n",
    "in our drive. also we need to set the img dimension and size which we are setting it to 32. and then we are creating a function to make it reusable in the future to take the image\n",
    "then resize and normalize it to the range between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Mj2af2_6VMt1"
   },
   "outputs": [],
   "source": [
    "ImgSize = (32, 32)\n",
    "Path_to_Dataset = '/content/Gesture Image Pre-Processed Data'\n",
    "\n",
    "def prep_and_load_img(ImgPath):\n",
    "    img = tf.io.read_file(ImgPath)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, ImgSize)\n",
    "    img = tf.cast(img, tf.float32) / 255.0\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dp1s7Yu07QD4"
   },
   "source": [
    "To avoid errors we are creating a function which takes the path as an argument and then checks and list every classes. and then it iterates through every class and convert the file into numpy array which makes our data ready to split. also we need to make sure that the directory exists and to do that we have to use isdir builtin function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "p4F0qUGs2upS"
   },
   "outputs": [],
   "source": [
    "\n",
    "def loading_data(Path_to_Dataset):\n",
    "    images = []\n",
    "    labels = []\n",
    "    classes = sorted(os.listdir(Path_to_Dataset))\n",
    "    cls_indices = {cls: idx for idx, cls in enumerate(classes)}\n",
    "\n",
    "    for cls in classes:\n",
    "        clsPath = os.path.join(Path_to_Dataset, cls)\n",
    "        if os.path.isdir(clsPath):\n",
    "            for file_name in os.listdir(clsPath):\n",
    "                imgPath = os.path.join(clsPath, file_name)\n",
    "                img = prep_and_load_img(imgPath)\n",
    "                images.append(img.numpy())\n",
    "                labels.append(cls_indices[cls])\n",
    "\n",
    "    return np.array(images), np.array(labels), len(classes)\n",
    "\n",
    "images, labels, num_classes = loading_data(Path_to_Dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZU-wLfGq8EPm"
   },
   "source": [
    "# Splitting our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "NCUPSaRg2uxw"
   },
   "outputs": [],
   "source": [
    "train_imgs, temp_images, train_lbls, temp_labels = train_test_split(images, labels, test_size=0.3, random_state=42)\n",
    "val_images, test_images, val_lbls, test_labels = train_test_split(temp_images, temp_labels, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kf4_oAXU9QLK"
   },
   "source": [
    "# Data Augmentation\n",
    "To improve our model and avoid overfitting we are using data augmentation to apply random transformation. to improve the models ability to generalize better we used different rotation range and also changed the other parameters but it didnt cause any overfitting or underfitting but with 50 it took longer to run the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "oq7Rgjt32u0h"
   },
   "outputs": [],
   "source": [
    "datagenr = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "datagenr.fit(train_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bifp-Vk47YGu"
   },
   "source": [
    "# Experiments and Discussions\n",
    "Beside running CNN, i tried VG16 and Densenet as well. out of all three models the best one CNN with accuracy of 99.26. i changed number of epochs, patience, filters and etc, and everytime the accuracy was different. the second best model was VGG16 with dropout 0.5, patience 3, epochs 20 and dense layer of 512 and the accuracy was 95. our last model that we trained and compiled our model on was Densenet with the same parameters as CNN and VGG16 and the accuracy was 91. below i have created a table to see the differences. After running and different models i decided to keep their results in table using pandas methods and left only the best model to keep the code clean and short and also easy to understand for future uses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "gNl7uifvkurq",
    "outputId": "05b70045-71ca-4712-d958-63fe9263ef32"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"df\",\n  \"rows\": 7,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"CNN\",\n          \"VGG16\",\n          \"DenseNet\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 25.648016074765486,\n        \"min\": 28.0,\n        \"max\": 99.26,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          99.26,\n          99.17,\n          91.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Dropout\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.5,\n        \"max\": 0.5,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Patience\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 5,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Epochs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": 10,\n        \"max\": 20,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          10\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Optimizer\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"adam\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Filters\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"32+64\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Dense\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 187,\n        \"min\": 128,\n        \"max\": 512,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          128\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-ddc09a23-257d-4fa0-8eca-fdce2218f103\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Dropout</th>\n",
       "      <th>Patience</th>\n",
       "      <th>Epochs</th>\n",
       "      <th>Optimizer</th>\n",
       "      <th>Filters</th>\n",
       "      <th>Dense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CNN</td>\n",
       "      <td>99.26</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>adam</td>\n",
       "      <td>32+64+168</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CNN</td>\n",
       "      <td>99.17</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>adam</td>\n",
       "      <td>32+64+168</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CNN</td>\n",
       "      <td>94.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>adam</td>\n",
       "      <td>32+64</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CNN</td>\n",
       "      <td>94.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>adam</td>\n",
       "      <td>32+65</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CNN</td>\n",
       "      <td>28.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>adam</td>\n",
       "      <td>32+66</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>VGG16</td>\n",
       "      <td>95.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>adam</td>\n",
       "      <td></td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DenseNet</td>\n",
       "      <td>91.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>adam</td>\n",
       "      <td></td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ddc09a23-257d-4fa0-8eca-fdce2218f103')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-ddc09a23-257d-4fa0-8eca-fdce2218f103 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-ddc09a23-257d-4fa0-8eca-fdce2218f103');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-9d5cfad6-c9b4-469f-ba5a-11801d065598\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9d5cfad6-c9b4-469f-ba5a-11801d065598')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-9d5cfad6-c9b4-469f-ba5a-11801d065598 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "  <div id=\"id_f0ba1c6e-b378-4442-96fa-b8033c4a1af3\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_f0ba1c6e-b378-4442-96fa-b8033c4a1af3 button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('df');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "      Model  Accuracy  Dropout  Patience  Epochs Optimizer    Filters  Dense\n",
       "0       CNN     99.26      0.5         5      10      adam  32+64+168    512\n",
       "1       CNN     99.17      0.5         3      20      adam  32+64+168    512\n",
       "2       CNN     94.00      0.5         3      20      adam      32+64    512\n",
       "3       CNN     94.00      0.5         3      15      adam      32+65    128\n",
       "4       CNN     28.00      0.5         0      10      adam      32+66    128\n",
       "5     VGG16     95.00      0.5         3      20      adam               512\n",
       "6  DenseNet     91.00      0.5         3      20      adam               512"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1iUzJAdo94kp"
   },
   "source": [
    "# Defining the Best Model - CNN\n",
    "I tried three different models but the best one was CNN with three different layers which are: convolutional layers, max pooling layers and dense layers. in the first version i tried using only 32 and 64 filters which gave me very unsatisfying accuracy 69%. but then i added 128 filters and also i changed the dense from 128 to 512 which increased the accuracy to 99.17%. after the number of epochs from 10 to 20 it stopped at epochs 14. then i changed the number of patience from 3 to 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "M57MUaGN285S"
   },
   "outputs": [],
   "source": [
    "def cnn_model(input_shape, num_classes):\n",
    "    model = Sequential([\n",
    "        Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=input_shape),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Conv2D(filters=128, kernel_size=(3, 3), activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W1RuY8CQ7Moz"
   },
   "source": [
    "# Traning the Best Model\n",
    "After trying different models and changing parameters we decided to train on our model which is CNN with the highest accuracy of 99.26. to do that we use our cnn_model function with two parameters input and number of classes. i changed the number of patience to 3 and epochs to 20 but since validation accuracy was constanly incearing it stop at epoch 14, therefor i tried patience 5 and number of epochs to 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ixKr_NNX7Jr-",
    "outputId": "922fa798-54e4-4ed8-836f-765a27f861c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1215/1215 [==============================] - 29s 22ms/step - loss: 1.6671 - accuracy: 0.4724 - val_loss: 0.1883 - val_accuracy: 0.9464\n",
      "Epoch 2/10\n",
      "1215/1215 [==============================] - 27s 22ms/step - loss: 0.5809 - accuracy: 0.8049 - val_loss: 0.1199 - val_accuracy: 0.9594\n",
      "Epoch 3/10\n",
      "1215/1215 [==============================] - 27s 22ms/step - loss: 0.3863 - accuracy: 0.8705 - val_loss: 0.0847 - val_accuracy: 0.9672\n",
      "Epoch 4/10\n",
      "1215/1215 [==============================] - 27s 23ms/step - loss: 0.3095 - accuracy: 0.8972 - val_loss: 0.0547 - val_accuracy: 0.9790\n",
      "Epoch 5/10\n",
      "1215/1215 [==============================] - 29s 24ms/step - loss: 0.2659 - accuracy: 0.9123 - val_loss: 0.0590 - val_accuracy: 0.9801\n",
      "Epoch 6/10\n",
      "1215/1215 [==============================] - 27s 22ms/step - loss: 0.2332 - accuracy: 0.9219 - val_loss: 0.0305 - val_accuracy: 0.9892\n",
      "Epoch 7/10\n",
      "1215/1215 [==============================] - 28s 23ms/step - loss: 0.2162 - accuracy: 0.9296 - val_loss: 0.0453 - val_accuracy: 0.9841\n",
      "Epoch 8/10\n",
      "1215/1215 [==============================] - 27s 22ms/step - loss: 0.1886 - accuracy: 0.9384 - val_loss: 0.0299 - val_accuracy: 0.9891\n",
      "Epoch 9/10\n",
      "1215/1215 [==============================] - 27s 22ms/step - loss: 0.1830 - accuracy: 0.9400 - val_loss: 0.0399 - val_accuracy: 0.9865\n",
      "Epoch 10/10\n",
      "1215/1215 [==============================] - 27s 22ms/step - loss: 0.1668 - accuracy: 0.9454 - val_loss: 0.0180 - val_accuracy: 0.9926\n",
      "261/261 [==============================] - 1s 3ms/step - loss: 0.0180 - accuracy: 0.9926\n",
      "Validation Accuracy: 0.9925525784492493\n"
     ]
    }
   ],
   "source": [
    "cnn_model = cnn_model(input_shape=(32, 32, 3), num_classes=num_classes)\n",
    "history = cnn_model.fit(datagenr.flow(train_imgs, train_lbls, batch_size=32),\n",
    "                        epochs=10,\n",
    "                        validation_data=(val_images, val_lbls),\n",
    "                        callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)])\n",
    "\n",
    "# Evaluate the Model\n",
    "val_loss, val_accuracy = cnn_model.evaluate(val_images, val_lbls)\n",
    "print(f\"Validation Accuracy: {val_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-_0thMJE7eZS"
   },
   "source": [
    "# Conclusion and findings\n",
    "The purpose of this project was to to create a pipeline for image classification task. after defining three different models ( Convolutional Neural Network, VGG16 model, and Densenet. I compare each of them using different, patience (becuase when a model is doing a great job and number of accuracy increases consistenly, the model stops training to avoid overfitting. therefor if you still want to know the how far the model can go and you dont want it to stop then we should use it.), DropOut Rate was use in all model to avoid overfitting and the result was good and maintained the high accuracy. the highest accuracy was achieved when we set the number of epochs to 10 but it was varied everytime in our different expremints. the more teh number of epochs the longer it takes to train our model. using combination of 3 different filters helped our models accuracy which was 32,64,128. the number of dense layer is also important and can affect our models accuracy, as you can see in our model when we increased our dense layer from 128 to 512 it increased our models accuracy. future work would be to try different parameters using VGG and pre trained models to improve their accuracy and to make sure if they can also reached our best model's accuracy."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
